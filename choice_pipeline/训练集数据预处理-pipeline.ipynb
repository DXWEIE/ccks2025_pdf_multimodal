{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.图片存储为image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [13:32<00:00, 15.93s/it]\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "base_dir = '/data/coding/patent_qa/train/'\n",
    "pdf_file_list  = [x for x in os.listdir(base_dir+'/documents/') if 'pdf' in x]\n",
    "\n",
    "for file_name in tqdm(pdf_file_list):\n",
    "    pdf_document = fitz.open(base_dir+'/documents/'+file_name)\n",
    "    os.makedirs(base_dir+'/pdf_img/'+file_name.split('.')[0],exist_ok=True)\n",
    "    # 获取第一页\n",
    "    for i in range(pdf_document.page_count):\n",
    "        page = pdf_document.load_page(i)  # 注意：页码从0开始\n",
    "        # 将页面转换为图像\n",
    "        pix = page.get_pixmap(dpi=600) # 这些文档600的dpi够了\n",
    "        pix.save(base_dir+'/pdf_img/'+file_name.split('.')[0]+'/'+str(i+1)+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/miniconda/envs/swift/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[INFO:swift] Successfully registered `/data/miniconda/envs/swift/lib/python3.10/site-packages/swift/llm/dataset/data/dataset_info.json`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-23 19:34:43 [importing.py:53] Triton module has been replaced with a placeholder.\n",
      "INFO 05-23 19:34:43 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 19:34:45,486\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "[INFO:swift] Loading the model using model_dir: /data/coding/llm_model/Qwen/Qwen2___5-VL-7B-Instruct/\n",
      "[INFO:swift] Setting torch_dtype: torch.bfloat16\n",
      "[WARNING:swift] Please install the package: `pip install \"decord\" -U`.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "[INFO:swift] Setting image_factor: 28. You can adjust this hyperparameter through the environment variable: `IMAGE_FACTOR`.\n",
      "[INFO:swift] Setting min_pixels: 3136. You can adjust this hyperparameter through the environment variable: `MIN_PIXELS`.\n",
      "[INFO:swift] Using environment variable `MAX_PIXELS`, Setting max_pixels: 1229312.\n",
      "[INFO:swift] Setting max_ratio: 200. You can adjust this hyperparameter through the environment variable: `MAX_RATIO`.\n",
      "[INFO:swift] Setting video_min_pixels: 100352. You can adjust this hyperparameter through the environment variable: `VIDEO_MIN_PIXELS`.\n",
      "[INFO:swift] Using environment variable `VIDEO_MAX_PIXELS`, Setting video_max_pixels: 50176.\n",
      "[INFO:swift] Using environment variable `VIDEO_TOTAL_PIXELS`, Setting video_total_pixels: 90316800.\n",
      "[INFO:swift] Setting frame_factor: 2. You can adjust this hyperparameter through the environment variable: `FRAME_FACTOR`.\n",
      "[INFO:swift] Setting fps: 2.0. You can adjust this hyperparameter through the environment variable: `FPS`.\n",
      "[INFO:swift] Setting fps_min_frames: 4. You can adjust this hyperparameter through the environment variable: `FPS_MIN_FRAMES`.\n",
      "[INFO:swift] Using environment variable `FPS_MAX_FRAMES`, Setting fps_max_frames: 2.\n",
      "[INFO:swift] Create the default_template for the infer_engine\n",
      "[INFO:swift] default_system: 'You are a helpful assistant.'\n",
      "[INFO:swift] response_prefix: ''\n",
      "[INFO:swift] agent_template: hermes\n",
      "[INFO:swift] max_length: 128000\n",
      "[INFO:swift] norm_bbox: none\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-23 19:34:54 [config.py:717] This model supports multiple tasks: {'score', 'reward', 'generate', 'classify', 'embed'}. Defaulting to 'generate'.\n",
      "WARNING 05-23 19:34:54 [arg_utils.py:1536] The model has a long context length (128000). This may causeOOM during the initial memory profiling phase, or result in low performance due to small KV cache size. Consider setting --max-model-len to a smaller value.\n",
      "INFO 05-23 19:34:54 [config.py:1770] Defaulting to use mp for distributed inference\n",
      "INFO 05-23 19:34:54 [llm_engine.py:240] Initializing a V0 LLM engine (v0.8.5.post1) with config: model='/data/coding/llm_model/Qwen/Qwen2___5-VL-7B-Instruct', speculative_config=None, tokenizer='/data/coding/llm_model/Qwen/Qwen2___5-VL-7B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=128000, download_dir=None, load_format=auto, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/coding/llm_model/Qwen/Qwen2___5-VL-7B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
      "WARNING 05-23 19:34:54 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 48 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n",
      "INFO 05-23 19:34:55 [cuda.py:292] Using Flash Attention backend.\n",
      "INFO 05-23 19:34:57 [__init__.py:239] Automatically detected platform cuda.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3347)\u001b[0;0m INFO 05-23 19:34:59 [multiproc_worker_utils.py:225] Worker ready; awaiting tasks\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3347)\u001b[0;0m INFO 05-23 19:35:01 [cuda.py:292] Using Flash Attention backend.\n",
      "INFO 05-23 19:35:02 [utils.py:1055] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3347)\u001b[0;0m INFO 05-23 19:35:02 [utils.py:1055] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3347)\u001b[0;0m INFO 05-23 19:35:02 [pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "INFO 05-23 19:35:02 [pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "INFO 05-23 19:35:02 [custom_all_reduce_utils.py:206] generating GPU P2P access cache in /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n",
      "INFO 05-23 19:35:16 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3347)\u001b[0;0m INFO 05-23 19:35:16 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n",
      "INFO 05-23 19:35:16 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_2456b64e'), local_subscribe_addr='ipc:///tmp/a5fed80b-f9f6-492d-be54-4ea3915e68ae', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3347)\u001b[0;0m INFO 05-23 19:35:16 [parallel_state.py:1004] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 1\n",
      "INFO 05-23 19:35:16 [parallel_state.py:1004] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 05-23 19:35:16 [model_runner.py:1108] Starting to load model /data/coding/llm_model/Qwen/Qwen2___5-VL-7B-Instruct...\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3347)\u001b[0;0m INFO 05-23 19:35:16 [model_runner.py:1108] Starting to load model /data/coding/llm_model/Qwen/Qwen2___5-VL-7B-Instruct...\n",
      "WARNING 05-23 19:35:17 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3347)\u001b[0;0m WARNING 05-23 19:35:17 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "INFO 05-23 19:35:17 [config.py:3614] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3347)\u001b[0;0m INFO 05-23 19:35:17 [config.py:3614] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/5 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  20% Completed | 1/5 [00:00<00:01,  3.27it/s]\n",
      "Loading safetensors checkpoint shards:  40% Completed | 2/5 [00:01<00:02,  1.10it/s]\n",
      "Loading safetensors checkpoint shards:  60% Completed | 3/5 [00:03<00:02,  1.16s/it]\n",
      "Loading safetensors checkpoint shards:  80% Completed | 4/5 [00:04<00:01,  1.30s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 5/5 [00:06<00:00,  1.36s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 5/5 [00:06<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-23 19:35:23 [loader.py:458] Loading weights took 6.19 seconds\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3347)\u001b[0;0m "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-23 19:35:23 [loader.py:458] Loading weights took 6.15 seconds\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3347)\u001b[0;0m INFO 05-23 19:35:23 [model_runner.py:1140] Model loading took 7.8681 GiB and 6.445108 seconds\n",
      "INFO 05-23 19:35:23 [model_runner.py:1140] Model loading took 7.8681 GiB and 6.489478 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorkerProcess pid=3347)\u001b[0;0m Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorkerProcess pid=3347)\u001b[0;0m INFO 05-23 19:36:40 [worker.py:287] Memory profiling takes 76.58 seconds\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3347)\u001b[0;0m INFO 05-23 19:36:40 [worker.py:287] the current vLLM instance can use total_gpu_memory (39.38GiB) x gpu_memory_utilization (0.90) = 35.44GiB\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3347)\u001b[0;0m INFO 05-23 19:36:40 [worker.py:287] model weights take 7.87GiB; non_torch_memory takes 0.41GiB; PyTorch activation peak memory takes 15.08GiB; the rest of the memory reserved for KV Cache is 12.09GiB.\n",
      "INFO 05-23 19:36:40 [worker.py:287] Memory profiling takes 76.68 seconds\n",
      "INFO 05-23 19:36:40 [worker.py:287] the current vLLM instance can use total_gpu_memory (39.38GiB) x gpu_memory_utilization (0.90) = 35.44GiB\n",
      "INFO 05-23 19:36:40 [worker.py:287] model weights take 7.87GiB; non_torch_memory takes 0.42GiB; PyTorch activation peak memory takes 15.08GiB; the rest of the memory reserved for KV Cache is 12.07GiB.\n",
      "INFO 05-23 19:36:40 [executor_base.py:112] # cuda blocks: 28252, # CPU blocks: 9362\n",
      "INFO 05-23 19:36:41 [executor_base.py:117] Maximum concurrency for 128000 tokens per request: 3.53x\n",
      "INFO 05-23 19:36:44 [model_runner.py:1450] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorkerProcess pid=3347)\u001b[0;0m INFO 05-23 19:36:44 [model_runner.py:1450] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:21<00:03,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorkerProcess pid=3347)\u001b[0;0m INFO 05-23 19:37:05 [custom_all_reduce.py:195] Registering 1995 cuda graph addresses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:26<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-23 19:37:10 [custom_all_reduce.py:195] Registering 1995 cuda graph addresses\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3347)\u001b[0;0m INFO 05-23 19:37:10 [model_runner.py:1592] Graph capturing finished in 26 secs, took 0.25 GiB\n",
      "INFO 05-23 19:37:10 [model_runner.py:1592] Graph capturing finished in 26 secs, took 0.25 GiB\n",
      "INFO 05-23 19:37:10 [llm_engine.py:437] init engine (profile, create kv cache, warmup model) took 106.90 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-23 19:37:11 [sampling_params.py:347] temperature 1e-06 is less than 0.01, which may cause numerical errors nan or inf in tensors. We have maxed it out to 0.01.\n"
     ]
    }
   ],
   "source": [
    "from swift.llm import InferEngine, InferRequest, PtEngine, RequestConfig, load_dataset\n",
    "from swift.plugin import InferStats\n",
    "from swift.llm import VllmEngine\n",
    "import os\n",
    "os.environ['VIDEO_MAX_PIXELS'] = '50176'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "os.environ[\"MAX_PIXELS\"] = \"1229312\"\n",
    "os.environ['FPS_MAX_FRAMES'] = \"2\"\n",
    "model_path = \"/data/coding/llm_model/Qwen/Qwen2___5-VL-7B-Instruct/\"\n",
    "# 多卡设置tensor_parallel_size为卡数\n",
    "engine = VllmEngine(model_path,model_type='qwen2_5_vl',gpu_memory_utilization=0.9,limit_mm_per_prompt={\"image\": 1},tensor_parallel_size=2)\n",
    "def infer_batch(engine, infer_requests):\n",
    "    request_config = RequestConfig(max_tokens=10240, temperature=0)\n",
    "    metric = InferStats()\n",
    "    resp_list = engine.infer(infer_requests, request_config)\n",
    "    response = resp_list[0].choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qwen_ocr_cn(img_path):\n",
    "    prompt=\"你是一个OCR专家，请提取以下图片中的所有文字内容，并原样返回。\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": img_path,\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    data = dict()\n",
    "    data['messages'] = messages\n",
    "    infer_requests = [InferRequest(**data)]\n",
    "    response = infer_batch(engine, infer_requests)\n",
    "    return response\n",
    "\n",
    "def qwen_ocr_en(img_path):\n",
    "    prompt=\"You are an OCR expert. Please extract all text from the following images, which have been converted from PDFs, and return the exact text content found in the attached image.\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": img_path,\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    data = dict()\n",
    "    data['messages'] = messages\n",
    "    infer_requests = [InferRequest(**data)]\n",
    "    response = infer_batch(engine, infer_requests)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:35<00:00,  5.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN100364694C   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:18<00:00,  7.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN101134389B   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:04<00:00,  6.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN101235824B   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [01:17<00:00,  5.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN101398011A   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:08<00:00,  7.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN102788006A   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:29<00:00,  4.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN102874588B   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:19<00:00,  3.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN103448299A   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [02:16<00:00,  8.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN103452849A   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:10<00:00,  7.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN103813555A   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:53<00:00,  4.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN1071381C   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:37<00:00,  5.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN110758510A   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:46<00:00,  6.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN110864395A   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:11<00:00,  7.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN111408437B   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:40<00:00,  6.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN111943458A   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [02:18<00:00,  8.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN111964678B   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:29<00:00,  5.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN112017362A   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:04<00:00,  6.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN112593737A   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:52<00:00,  6.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN201677068U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:48<00:00,  5.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN201820326U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:30<00:00,  6.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN202263810U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:33<00:00,  5.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN202280858U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:18<00:00,  4.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN202612621U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:21<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN202613717U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:18<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN2078861U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:42<00:00,  5.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN211476607U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:44<00:00,  6.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN211674871U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:50<00:00,  6.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN212384434U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:36<00:00,  6.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN212507478U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:33<00:00,  6.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN212643037U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:45<00:00,  6.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN212772760U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:48<00:00,  6.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN212822463U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [01:19<00:00,  7.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN213315909U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:29<00:00,  4.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN213444549U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:43<00:00,  6.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN213492225U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:56<00:00,  7.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN213537655U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:31<00:00,  6.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN213655898U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:47<00:00,  6.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN213681400U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:36<00:00,  5.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN213794681U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:29<00:00,  5.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN213838924U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:54<00:00,  6.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN213995317U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:56<00:00,  6.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN214892742U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:50<00:00,  6.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN215045900U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:37<00:00,  5.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN215924291U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:20<00:00,  4.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN216066104U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:40<00:00,  6.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN216281372U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:37<00:00,  6.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN216346248U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:38<00:00,  6.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN216371815U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:33<00:00,  6.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN216803763U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:32<00:00,  5.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN217268780U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:32<00:00,  6.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN217479855U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:43<00:00,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN218108941U   ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 进行ocr\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "base_dir = '/data/coding/patent_qa/train/'\n",
    "pdf_file_list = [x for x in os.listdir(base_dir+'/pdf_img/')]\n",
    "for pdf_file in pdf_file_list:\n",
    "    file_name = pdf_file.split('.')[0]\n",
    "    file_list = [x for x in os.listdir(base_dir+'/pdf_img/'+file_name) if 'jpg' in x] # pdf文件存储的jpg\n",
    "    os.makedirs(base_dir+'/pdf_ocr/'+file_name,exist_ok=True)\n",
    "    for k in tqdm(range(len(file_list))):\n",
    "        img_path = base_dir+'/pdf_img/'+file_name + '/' + file_list[k]\n",
    "        page_num = int(file_list[k].split('.')[0])\n",
    "        # ocr\n",
    "        response = qwen_ocr_cn(img_path)\n",
    "        # 保存ocr结果为txt\n",
    "        with open(base_dir+f'/pdf_ocr/{file_name}/{page_num}.txt', 'w', encoding='utf-8') as text_file:\n",
    "            text_file.write(response)\n",
    "    print(file_name,'  ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. OCR的结果存入向量库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0,1'\n",
    "os.environ[\"MAX_PIXELS\"] = '1229312' # 1003520\n",
    "from gme_inference import GmeQwen2VL\n",
    "gme = GmeQwen2VL('/home/octopus/data/dxw/pretrain_model/iic/gme-Qwen2-VL-7B-Instruct',max_image_tokens=1280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from warnings import filterwarnings\n",
    "# 过滤掉一些警告\n",
    "filterwarnings(\"ignore\")\n",
    "base_dir = '/data/coding/patent_qa/train/'\n",
    "pdf_file_list = [x for x in os.listdir(base_dir+'/pdf_img/')]\n",
    "files_total_cnt = 0\n",
    "for pdf_file in pdf_file_list:\n",
    "    file_name = pdf_file.split('.')[0]\n",
    "    file_list = [x for x in os.listdir(base_dir+'/pdf_ocr/'+file_name) if 'txt' in x]\n",
    "    files_total_cnt +=len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文件有多个，每个都需要存映射关系\n",
    "ocr_page_num_list = []\n",
    "ocr_name_list = []\n",
    "ocr_vectors = np.empty((files_total_cnt, 3584)) # 向量维度是3584维\n",
    "idx = 0\n",
    "for pdf_file in pdf_file_list:\n",
    "    file_name = pdf_file.split('.')[0]\n",
    "    file_list = [x for x in os.listdir(base_dir+'/pdf_ocr/'+file_name) if 'txt' in x] # pdf文件存储的jpg\n",
    "    for k in range(len(file_list)):  \n",
    "        text_path = base_dir+'/pdf_ocr/'+file_name + '/' + file_list[k]\n",
    "        with open(text_path, 'r', encoding='utf-8') as f:\n",
    "            text_content = f.read()\n",
    "        e_text = gme.get_text_embeddings(texts=[text_content])\n",
    "        ocr_vectors[idx] = e_text[0].to('cpu').numpy()\n",
    "        page_num = int(file_list[k].split('.')[0])\n",
    "        ocr_page_num_list.append(page_num)\n",
    "        ocr_name_list.append(file_name)\n",
    "        idx+=1\n",
    "# 映射关系存储到pandas里面比较方便\n",
    "ocr_page_num_mapping = pd.DataFrame({'index': range(len(ocr_page_num_list)), 'page_num': ocr_page_num_list, 'file_name': ocr_name_list})\n",
    "# 将向量和页码映射关系存储到文件\n",
    "np.save('ocr_vectors.npy', ocr_vectors)\n",
    "ocr_page_num_mapping.to_csv('ocr_page_num_mapping.csv', index=False) # 存储映射关系\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 图片的结果存入向量库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from warnings import filterwarnings\n",
    "# 过滤掉一些警告\n",
    "filterwarnings(\"ignore\")\n",
    "base_dir = '/data/coding/patent_qa/train/'\n",
    "pdf_file_list = [x for x in os.listdir(base_dir+'/pdf_img/')]\n",
    "files_total_cnt = 0\n",
    "for pdf_file in pdf_file_list:\n",
    "    file_name = pdf_file.split('.')[0]\n",
    "    file_list = [x for x in os.listdir(base_dir+'/pdf_img/'+file_name) if 'jpg' in x]\n",
    "    files_total_cnt +=len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文件有多个，每个都需要存映射关系\n",
    "img_page_num_list = []\n",
    "img_name_list = []\n",
    "img_vectors = np.empty((files_total_cnt, 3584)) # 向量维度是3584维\n",
    "idx = 0\n",
    "for pdf_file in pdf_file_list:\n",
    "    file_name = pdf_file.split('.')[0]\n",
    "    file_list = [x for x in os.listdir(base_dir+'/pdf_img/'+file_name) if 'jpg' in x] # pdf文件存储的jpg\n",
    "    for k in range(len(file_list)):  \n",
    "        image_path = base_dir+'/pdf_img/'+file_name + '/' + file_list[k]\n",
    "        e_text = gme.get_image_embeddings(images=[image_path])\n",
    "        img_vectors[idx] = e_text[0].to('cpu').numpy()\n",
    "        page_num = int(file_list[k].split('.')[0])\n",
    "        img_page_num_list.append(page_num)\n",
    "        img_name_list.append(file_name)\n",
    "        idx+=1\n",
    "# 映射关系存储到pandas里面比较方便\n",
    "img_page_num_mapping = pd.DataFrame({'index': range(len(img_page_num_list)), 'page_num': img_page_num_list, 'file_name': img_name_list})\n",
    "# 将向量和页码映射关系存储到文件\n",
    "np.save('pdf_img_vectors.npy', img_vectors)\n",
    "img_page_num_mapping.to_csv('pdf_img_page_num_mapping.csv', index=False) # 存储映射关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 读取问题生成问题的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 问题的vector进行保存\n",
    "question_vectors = np.empty((len(df_question), 3584))\n",
    "for i in range(len(df_question)):\n",
    "    question = df_question.loc[i,'question']\n",
    "    document_name = df_question.loc[i,'document']\n",
    "    options = df_question.loc[i,'options']\n",
    "    true_answer = df_question.loc[i,'answer']\n",
    "    full_question = question + ' '.join(options)\n",
    "    query_vec = gme.get_text_embeddings(texts=[full_question])\n",
    "    question_vectors[i] = query_vec[0].to('cpu').numpy()\n",
    "# 保存问题的向量\n",
    "np.save('all_question_vectors.npy', question_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>document</th>\n",
       "      <th>options</th>\n",
       "      <th>answer</th>\n",
       "      <th>group</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>根据专利文本，以下哪个是该货物靠边规整处理机构的主要功能？</td>\n",
       "      <td>CN213444549U.pdf</td>\n",
       "      <td>[A. 实现对货物的加热处理。, B. 实现对货物的靠边规整处理。, C. 实现对货物的分拣...</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>根据专利文本，关于转辊倾斜角度的描述，以下哪项是正确的？</td>\n",
       "      <td>CN213444549U.pdf</td>\n",
       "      <td>[A. 转辊的倾斜角度为15-20°。, B. 转辊的倾斜角度为5-10°。, C. 转辊的...</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>在文件中第5页提供的图片中，编号为4的部件是什么？</td>\n",
       "      <td>CN213444549U.pdf</td>\n",
       "      <td>[A. 转轴, B. 侧板, C. 联动皮带, D. 支架]</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>在文件中第5页提供的图片中，编号为5的部件是什么？</td>\n",
       "      <td>CN213444549U.pdf</td>\n",
       "      <td>[A. 转辊, B. 支架, C. 联动皮带, D. 侧板]</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>在文件中第5页的示意图中，如果货物靠着侧板1移动，那么最可能的原因是？</td>\n",
       "      <td>CN213444549U.pdf</td>\n",
       "      <td>[A. 转辊2是水平设置的, B. 联动皮带4松动, C. 货物移动到了侧边并且不能再移动,...</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              question          document  \\\n",
       "0        根据专利文本，以下哪个是该货物靠边规整处理机构的主要功能？  CN213444549U.pdf   \n",
       "1         根据专利文本，关于转辊倾斜角度的描述，以下哪项是正确的？  CN213444549U.pdf   \n",
       "2            在文件中第5页提供的图片中，编号为4的部件是什么？  CN213444549U.pdf   \n",
       "3            在文件中第5页提供的图片中，编号为5的部件是什么？  CN213444549U.pdf   \n",
       "4  在文件中第5页的示意图中，如果货物靠着侧板1移动，那么最可能的原因是？  CN213444549U.pdf   \n",
       "\n",
       "                                             options answer  group  id  \n",
       "0  [A. 实现对货物的加热处理。, B. 实现对货物的靠边规整处理。, C. 实现对货物的分拣...      B      1   1  \n",
       "1  [A. 转辊的倾斜角度为15-20°。, B. 转辊的倾斜角度为5-10°。, C. 转辊的...      B      1   2  \n",
       "2                     [A. 转轴, B. 侧板, C. 联动皮带, D. 支架]      C      2   3  \n",
       "3                     [A. 转辊, B. 支架, C. 联动皮带, D. 侧板]      B      2   4  \n",
       "4  [A. 转辊2是水平设置的, B. 联动皮带4松动, C. 货物移动到了侧边并且不能再移动,...      C      3   5  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_question = pd.read_json(\"/data/coding/patent_qa/train/questions.jsonl\",lines=True)\n",
    "df_question.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_answer(document_name,question,options,i):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_question)):\n",
    "    question = df_question.loc[i,'question']\n",
    "    document_name = df_question.loc[i,'document']\n",
    "    options = df_question.loc[i,'options']\n",
    "    true_answer = df_question.loc[i,'answer']\n",
    "    full_question = question + ' '.join(options)\n",
    "    if \"第\" in question and \"页\" in question and \"图\": # 问题含有图片\n",
    "        pic_page_num = re.findall(r\"第(\\d+)页\", question)[0]\n",
    "        pic_page_num = int(pic_page_num)\n",
    "        text_answer = get_text_answer_pic_question(document_name,pic_page_num,question,options,i) # 使用含有文本来回答\n",
    "        image_answer = get_img_answer_pic_question(document_name,pic_page_num,question,options,i) # 仅使用目标图像来回答\n",
    "    else:\n",
    "        text_answer = get_text_answer(document_name,question,options,i) # 使用文本来回答\n",
    "        image_answer = get_img_answer(document_name,question,options,i) # 使用图像来回答\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_question)):\n",
    "    question = df_question.loc[i,'question']\n",
    "    document_name = df_question.loc[i,'document']\n",
    "    options = df_question.loc[i,'options']\n",
    "    true_answer = df_question.loc[i,'answer']\n",
    "    full_question = question + ' '.join(options)\n",
    "    if \"第\" in question and \"页\" in question and \"图\": # 问题含有图片\n",
    "        pic_page_num = re.findall(r\"第(\\d+)页\", question)[0]\n",
    "        pic_page_num = int(pic_page_num)\n",
    "        text_answer = get_text_answer_pic_question(document_name,pic_page_num,full_question) # 使用含有文本来回答\n",
    "        image_answer = get_img_answer_pic_question(document_name,pic_page_num,full_question) # 仅使用目标图像来回答\n",
    "    else:\n",
    "        text_answer = get_text_answer(document_name,full_question) # 使用文本来回答\n",
    "        image_answer = get_img_answer(document_name,full_question) # 使用图像来回答\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
