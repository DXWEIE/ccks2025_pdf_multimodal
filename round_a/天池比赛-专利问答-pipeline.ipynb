{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.图片存储为image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "base_dir = '/data/coding/patent_qa/train/'\n",
    "pdf_file_list  = [x for x in os.listdir(base_dir+'/documents/') if 'pdf' in x]\n",
    "\n",
    "for file_name in tqdm(pdf_file_list):\n",
    "    pdf_document = fitz.open(base_dir+'/documents/'+file_name)\n",
    "    os.makedirs(base_dir+'/pdf_img/'+file_name.split('.')[0],exist_ok=True)\n",
    "    # 获取第一页\n",
    "    for i in range(pdf_document.page_count):\n",
    "        page = pdf_document.load_page(i)  # 注意：页码从0开始\n",
    "        # 将页面转换为图像\n",
    "        pix = page.get_pixmap(dpi=600) # 这些文档600的dpi够了\n",
    "        pix.save(base_dir+'/pdf_img/'+file_name.split('.')[0]+'/'+str(i+1)+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swift.llm import InferEngine, InferRequest, PtEngine, RequestConfig, load_dataset\n",
    "from swift.plugin import InferStats\n",
    "from swift.llm import VllmEngine\n",
    "import os\n",
    "os.environ['VIDEO_MAX_PIXELS'] = '50176'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "os.environ[\"MAX_PIXELS\"] = \"1229312\"\n",
    "os.environ['FPS_MAX_FRAMES'] = \"2\"\n",
    "model_path = \"/data/coding/llm_model/Qwen/Qwen2___5-VL-7B-Instruct/\"\n",
    "# 多卡设置tensor_parallel_size为卡数\n",
    "engine = VllmEngine(model_path,model_type='qwen2_5_vl',gpu_memory_utilization=0.9,limit_mm_per_prompt={\"image\": 1},tensor_parallel_size=2)\n",
    "def infer_batch(engine, infer_requests):\n",
    "    request_config = RequestConfig(max_tokens=10240, temperature=0)\n",
    "    metric = InferStats()\n",
    "    resp_list = engine.infer(infer_requests, request_config)\n",
    "    response = resp_list[0].choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qwen_ocr_cn(img_path):\n",
    "    prompt=\"你是一个OCR专家，请提取以下图片中的所有文字内容，并原样返回。\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": img_path,\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    data = dict()\n",
    "    data['messages'] = messages\n",
    "    infer_requests = [InferRequest(**data)]\n",
    "    response = infer_batch(engine, infer_requests)\n",
    "    return response\n",
    "\n",
    "def qwen_ocr_en(img_path):\n",
    "    prompt=\"You are an OCR expert. Please extract all text from the following images, which have been converted from PDFs, and return the exact text content found in the attached image.\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": img_path,\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    data = dict()\n",
    "    data['messages'] = messages\n",
    "    infer_requests = [InferRequest(**data)]\n",
    "    response = infer_batch(engine, infer_requests)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行ocr\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "base_dir = '/data/coding/patent_qa/train/'\n",
    "pdf_file_list = [x for x in os.listdir(base_dir+'/pdf_img/')]\n",
    "for pdf_file in pdf_file_list:\n",
    "    file_name = pdf_file.split('.')[0]\n",
    "    file_list = [x for x in os.listdir(base_dir+'/pdf_img/'+file_name) if 'jpg' in x] # pdf文件存储的jpg\n",
    "    os.makedirs(base_dir+'/pdf_ocr/'+file_name,exist_ok=True)\n",
    "    for k in tqdm(range(len(file_list))):\n",
    "        img_path = base_dir+'/pdf_img/'+file_name + '/' + file_list[k]\n",
    "        page_num = int(file_list[k].split('.')[0])\n",
    "        # ocr\n",
    "        response = qwen_ocr_cn(img_path)\n",
    "        # 保存ocr结果为txt\n",
    "        with open(base_dir+f'/pdf_ocr/{file_name}/{page_num}.txt', 'w', encoding='utf-8') as text_file:\n",
    "            text_file.write(response)\n",
    "    print(file_name,'  ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. OCR的结果存入向量库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0,1'\n",
    "os.environ[\"MAX_PIXELS\"] = '1229312' # 1003520\n",
    "from gme_inference import GmeQwen2VL\n",
    "gme = GmeQwen2VL(model_name='/data/coding/llm_model/iic/gme-Qwen2-VL-7B-Instruct',max_image_tokens=1280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from warnings import filterwarnings\n",
    "# 过滤掉一些警告\n",
    "filterwarnings(\"ignore\")\n",
    "base_dir = '/data/coding/patent_qa/train/'\n",
    "pdf_file_list = [x for x in os.listdir(base_dir+'/pdf_img/')]\n",
    "files_total_cnt = 0\n",
    "for pdf_file in pdf_file_list:\n",
    "    file_name = pdf_file.split('.')[0]\n",
    "    file_list = [x for x in os.listdir(base_dir+'/pdf_ocr/'+file_name) if 'txt' in x]\n",
    "    files_total_cnt +=len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文件有多个，每个都需要存映射关系\n",
    "ocr_page_num_list = []\n",
    "ocr_name_list = []\n",
    "ocr_vectors = np.empty((files_total_cnt, 3584)) # 向量维度是3584维\n",
    "idx = 0\n",
    "for pdf_file in pdf_file_list:\n",
    "    file_name = pdf_file.split('.')[0]\n",
    "    file_list = [x for x in os.listdir(base_dir+'/pdf_ocr/'+file_name) if 'txt' in x] # pdf文件存储的jpg\n",
    "    for k in range(len(file_list)):  \n",
    "        text_path = base_dir+'/pdf_ocr/'+file_name + '/' + file_list[k]\n",
    "        with open(text_path, 'r', encoding='utf-8') as f:\n",
    "            text_content = f.read()\n",
    "        e_text = gme.get_text_embeddings(texts=[text_content])\n",
    "        ocr_vectors[idx] = e_text[0].to('cpu').numpy()\n",
    "        page_num = int(file_list[k].split('.')[0])\n",
    "        ocr_page_num_list.append(page_num)\n",
    "        ocr_name_list.append(file_name)\n",
    "        idx+=1\n",
    "# 映射关系存储到pandas里面比较方便\n",
    "ocr_page_num_mapping = pd.DataFrame({'index': range(len(ocr_page_num_list)), 'page_num': ocr_page_num_list, 'file_name': ocr_name_list})\n",
    "# 将向量和页码映射关系存储到文件\n",
    "np.save('train_ocr_vectors.npy', ocr_vectors)\n",
    "ocr_page_num_mapping.to_csv('train_ocr_page_num_mapping.csv', index=False) # 存储映射关系\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 图片的结果存入向量库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from warnings import filterwarnings\n",
    "# 过滤掉一些警告\n",
    "filterwarnings(\"ignore\")\n",
    "base_dir = '/data/coding/patent_qa/train/'\n",
    "pdf_file_list = [x for x in os.listdir(base_dir+'/pdf_img/')]\n",
    "files_total_cnt = 0\n",
    "for pdf_file in pdf_file_list:\n",
    "    file_name = pdf_file.split('.')[0]\n",
    "    file_list = [x for x in os.listdir(base_dir+'/pdf_img/'+file_name) if 'jpg' in x]\n",
    "    files_total_cnt +=len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文件有多个，每个都需要存映射关系\n",
    "img_page_num_list = []\n",
    "img_name_list = []\n",
    "img_vectors = np.empty((files_total_cnt, 3584)) # 向量维度是3584维\n",
    "idx = 0\n",
    "for pdf_file in pdf_file_list:\n",
    "    file_name = pdf_file.split('.')[0]\n",
    "    file_list = [x for x in os.listdir(base_dir+'/pdf_img/'+file_name) if 'jpg' in x] # pdf文件存储的jpg\n",
    "    for k in range(len(file_list)):  \n",
    "        image_path = base_dir+'/pdf_img/'+file_name + '/' + file_list[k]\n",
    "        e_text = gme.get_image_embeddings(images=[image_path])\n",
    "        img_vectors[idx] = e_text[0].to('cpu').numpy()\n",
    "        page_num = int(file_list[k].split('.')[0])\n",
    "        img_page_num_list.append(page_num)\n",
    "        img_name_list.append(file_name)\n",
    "        idx+=1\n",
    "# 映射关系存储到pandas里面比较方便\n",
    "img_page_num_mapping = pd.DataFrame({'index': range(len(img_page_num_list)), 'page_num': img_page_num_list, 'file_name': img_name_list})\n",
    "# 将向量和页码映射关系存储到文件\n",
    "np.save('train_pdf_img_vectors.npy', img_vectors)\n",
    "img_page_num_mapping.to_csv('train_pdf_img_page_num_mapping.csv', index=False) # 存储映射关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 读取问题生成问题的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question = pd.read_json('/data/coding/patent_qa/train/questions.jsonl',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 问题的vector进行保存\n",
    "question_vectors = np.empty((len(df_question), 3584))\n",
    "for i in range(len(df_question)):\n",
    "    question = df_question.loc[i,'question']\n",
    "    document_name = df_question.loc[i,'document']\n",
    "    options = df_question.loc[i,'options']\n",
    "    true_answer = df_question.loc[i,'answer']\n",
    "    full_question = question + ' '.join(options)\n",
    "    query_vec = gme.get_text_embeddings(texts=[full_question])\n",
    "    question_vectors[i] = query_vec[0].to('cpu').numpy()\n",
    "# 保存问题的向量\n",
    "np.save('all_train_question_vectors.npy', question_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>document</th>\n",
       "      <th>options</th>\n",
       "      <th>answer</th>\n",
       "      <th>group</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>根据专利文本，以下哪个是该货物靠边规整处理机构的主要功能？</td>\n",
       "      <td>CN213444549U.pdf</td>\n",
       "      <td>[A. 实现对货物的加热处理。, B. 实现对货物的靠边规整处理。, C. 实现对货物的分拣...</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>根据专利文本，关于转辊倾斜角度的描述，以下哪项是正确的？</td>\n",
       "      <td>CN213444549U.pdf</td>\n",
       "      <td>[A. 转辊的倾斜角度为15-20°。, B. 转辊的倾斜角度为5-10°。, C. 转辊的...</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>在文件中第5页提供的图片中，编号为4的部件是什么？</td>\n",
       "      <td>CN213444549U.pdf</td>\n",
       "      <td>[A. 转轴, B. 侧板, C. 联动皮带, D. 支架]</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>在文件中第5页提供的图片中，编号为5的部件是什么？</td>\n",
       "      <td>CN213444549U.pdf</td>\n",
       "      <td>[A. 转辊, B. 支架, C. 联动皮带, D. 侧板]</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>在文件中第5页的示意图中，如果货物靠着侧板1移动，那么最可能的原因是？</td>\n",
       "      <td>CN213444549U.pdf</td>\n",
       "      <td>[A. 转辊2是水平设置的, B. 联动皮带4松动, C. 货物移动到了侧边并且不能再移动,...</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              question          document  \\\n",
       "0        根据专利文本，以下哪个是该货物靠边规整处理机构的主要功能？  CN213444549U.pdf   \n",
       "1         根据专利文本，关于转辊倾斜角度的描述，以下哪项是正确的？  CN213444549U.pdf   \n",
       "2            在文件中第5页提供的图片中，编号为4的部件是什么？  CN213444549U.pdf   \n",
       "3            在文件中第5页提供的图片中，编号为5的部件是什么？  CN213444549U.pdf   \n",
       "4  在文件中第5页的示意图中，如果货物靠着侧板1移动，那么最可能的原因是？  CN213444549U.pdf   \n",
       "\n",
       "                                             options answer  group  id  \n",
       "0  [A. 实现对货物的加热处理。, B. 实现对货物的靠边规整处理。, C. 实现对货物的分拣...      B      1   1  \n",
       "1  [A. 转辊的倾斜角度为15-20°。, B. 转辊的倾斜角度为5-10°。, C. 转辊的...      B      1   2  \n",
       "2                     [A. 转轴, B. 侧板, C. 联动皮带, D. 支架]      C      2   3  \n",
       "3                     [A. 转辊, B. 支架, C. 联动皮带, D. 侧板]      B      2   4  \n",
       "4  [A. 转辊2是水平设置的, B. 联动皮带4松动, C. 货物移动到了侧边并且不能再移动,...      C      3   5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_question = pd.read_json(\"/data/coding/patent_qa/train/questions.jsonl\",lines=True)\n",
    "df_question.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "quesion_vector = np.load('all_train_question_vectors.npy')\n",
    "ocr_page_num_mapping = pd.read_csv('train_ocr_page_num_mapping.csv')\n",
    "train_ocr_vectors = np.load('train_ocr_vectors.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "querstion_idx = 0\n",
    "document_name = df_question.document[querstion_idx].split('.')[0]\n",
    "vec_idx = ocr_page_num_mapping[ocr_page_num_mapping['file_name']==document_name]['index'].values\n",
    "candidate_vec = train_ocr_vectors[vec_idx]\n",
    "query_vec = quesion_vector[querstion_idx]\n",
    "cos_sim = np.dot(candidate_vec, query_vec) / (np.linalg.norm(candidate_vec) * np.linalg.norm(query_vec))\n",
    "# 获取最相似的k个索引\n",
    "k = 5\n",
    "top_k_indices = np.argsort(cos_sim)[-k:][::-1]\n",
    "retrived_idx = vec_idx[top_k_indices] # 最相近的5个\n",
    "retrived_page_num = ocr_page_num_mapping.loc[df_idx]['page_num'].to_list()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 1, 2, 6]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrived_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_text_embedding(base_dir,document_name,quesion_idx,top_k):\n",
    "    document_name = df_question.document[querstion_idx].split('.')[0]\n",
    "    vec_idx = ocr_page_num_mapping[ocr_page_num_mapping['file_name']==document_name]['index'].values\n",
    "    candidate_vec = train_ocr_vectors[vec_idx]\n",
    "    query_vec = quesion_vector[querstion_idx]\n",
    "    cos_sim = np.dot(candidate_vec, query_vec) / (np.linalg.norm(candidate_vec) * np.linalg.norm(query_vec))\n",
    "    # 获取最相似的top_k个索引\n",
    "    top_k_indices = np.argsort(cos_sim)[-top_k:][::-1]\n",
    "    retrived_idx = vec_idx[top_k_indices] # 最相近的top_k个\n",
    "    retrived_page_num = ocr_page_num_mapping.loc[df_idx]['page_num'].to_list()\n",
    "    text_list = []\n",
    "    for i in range(len(retrived_page_num)):\n",
    "        text_file = base_dir + '/pdf_ocr/' + document_name + '/' + str(page_num) +'.txt'\n",
    "        with open(text_file,'r'):\n",
    "            text_list.append(f.read())\n",
    "    return text_list # 返回一个list,大小最大为top_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 试一下qwen3的llm是不是效果好一些\n",
    "from vllm import LLM, SamplingParams\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "text_qa_llm = LLM(model=\"/home/octopus/data/dxw/pretrain_model/Qwen/Qwen3-8B\",gpu_memory_utilization=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_answer(document_name,question,options,quesion_idx):\n",
    "    prompt=\"你是一个专利内容分析专家，请根据我提供的专利内容回答我的单选题。\\n\"\n",
    "    question = \"【我的问题】【\"\n",
    "    question += (question +\"】\\n\")\n",
    "    question += \"【选项】【\"\n",
    "    question += (' '.join(options) + \"】\\n\")\n",
    "    question += (\"请在分析我提供的专利问题后回答我的单选题，回答选项字母。专利内容为：\\n\")\n",
    "    retrived_list = get_similar_text_embedding(base_dir,document_name,quesion_idx,top_k=3)\n",
    "    question += '\\n'.join(retrived_list)\n",
    "    question += (\"请你分析专利内容后，回答我的单选题，回答选项字母，你的答案为：\\n\")\n",
    "    sampling_params = SamplingParams(temperature=0)\n",
    "    outputs = text_qa_llm.generate(question,sampling_params)\n",
    "    return outputs[0].outputs[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pdf_image_vectors = np.load(\"train_pdf_image_vectors.npy\")\n",
    "train_pdf_image_page_num_mapping = pd.read_csv('train_pdf_img_page_num_mapping.csv')\n",
    "def get_similar_image_embedding(base_dir,document_name,quesion_idx,top_k):\n",
    "    document_name = df_question.document[querstion_idx].split('.')[0]\n",
    "    vec_idx = train_pdf_image_page_num_mapping[train_pdf_image_page_num_mapping['file_name']==document_name]['index'].values\n",
    "    candidate_vec = train_pdf_image_vectors[vec_idx]\n",
    "    query_vec = quesion_vector[querstion_idx]\n",
    "    cos_sim = np.dot(candidate_vec, query_vec) / (np.linalg.norm(candidate_vec) * np.linalg.norm(query_vec))\n",
    "    # 获取最相似的top_k个索引\n",
    "    top_k_indices = np.argsort(cos_sim)[-top_k:][::-1]\n",
    "    retrived_idx = vec_idx[top_k_indices] # 最相近的top_k个\n",
    "    retrived_page_num = train_pdf_image_page_num_mapping.loc[df_idx]['page_num'].to_list()\n",
    "    image_list = []\n",
    "    for i in range(len(retrived_page_num)):\n",
    "        image_file = base_dir + '/pdf_img/' + document_name + '/' + str(page_num) +'.jpg'\n",
    "        image_list.append(image_file)\n",
    "    return image_list # 返回一个list,大小最大为top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swift.llm import InferEngine, InferRequest, PtEngine, RequestConfig, load_dataset\n",
    "from swift.plugin import InferStats\n",
    "from swift.llm import VllmEngine\n",
    "import os\n",
    "os.environ['VIDEO_MAX_PIXELS'] = '50176'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "os.environ[\"MAX_PIXELS\"] = \"1229312\"\n",
    "os.environ['FPS_MAX_FRAMES'] = \"2\"\n",
    "model_path = \"/data/coding/llm_model/Qwen/Qwen2___5-VL-7B-Instruct\"\n",
    "engine = VllmEngine(model_path,model_type='qwen2_5_vl',gpu_memory_utilization=0.9,limit_mm_per_prompt={\"image\": 3})\n",
    "def infer_batch(engine, infer_requests):\n",
    "    request_config = RequestConfig(max_tokens=1024, temperature=0)\n",
    "    metric = InferStats()\n",
    "    resp_list = engine.infer(infer_requests, request_config)\n",
    "    response = resp_list[0].choices[0].message.content\n",
    "    return response\n",
    "\n",
    "def get_image_answer(document_name,question,options,quesion_idx):\n",
    "    prompt=\"你是一个专利内容分析专家，请根据我提供的专利内容回答我的单选题。\\n\"\n",
    "    question1 = \"【我的问题】【\"\n",
    "    question1 += (question +\"】\\n\")\n",
    "    question1 += \"【选项】【\"\n",
    "    question1 += (' '.join(options) + \"】\\n\")\n",
    "    question1 += (\"请在分析我提供的专利问题后回答我的单选题，回答选项字母。专利内容为：\\n\")\n",
    "    retrived_list = get_similar_image_embedding(base_dir,document_name,ocr_page_num_mapping,quesion_idx,top_k=2)\n",
    "    question2 = (\"请你分析专利内容后，回答我的单选题，回答选项字母，你的答案为：\\n\")\n",
    "    if len(retrived_list)>1:\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": question1},\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"image\": retrived_list[0],\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"image\": retrived_list[1],\n",
    "                    },\n",
    "                    {\"type\": \"text\", \"text\": question2},\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "    else:\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": question1},\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"image\": retrived_list[0],\n",
    "                    },\n",
    "                    {\"type\": \"text\", \"text\": question2},\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "    data = dict()\n",
    "    data['messages'] = messages\n",
    "    infer_requests = [InferRequest(**data)]\n",
    "    response = infer_batch(engine, infer_requests)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 给定了图片的情况下，有图片本身，也需要召回对应的文本\n",
    "def get_mix_answer(document_name,pic_page_num,question,options,question_idx):\n",
    "    prompt=\"你是一个专利内容分析专家，请根据我提供的专利内容回答我的单选题。\\n\"\n",
    "    question1 = \"【我的问题】【\"\n",
    "    question1 += (question +\"】\\n\")\n",
    "    question1 += \"【选项】【\"\n",
    "    question1 += (' '.join(options) + \"】\\n\")\n",
    "    question1 += (\"请在分析我提供的专利问题后回答我的单选题，回答选项字母。专利内容为：\\n\")\n",
    "    retrived_list = get_similar_text_embedding(base_dir,document_name,ocr_page_num_mapping,quesion_idx,top_k=2)\n",
    "    question2 = (\"请你分析专利内容后，回答我的单选题，回答选项字母，你的答案为：\\n\")\n",
    "    messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": question1},\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"image\": base_dir + '/pdf_img/' + document_name + '/' + str(page_num) +'.jpg',\n",
    "                    },\n",
    "                    {\"type\": \"text\", \"text\": '\\n'.join(retrived_list)},\n",
    "                    {\"type\": \"text\", \"text\": question2},\n",
    "                ],\n",
    "            }\n",
    "    ]\n",
    "    data = dict()\n",
    "    data['messages'] = messages\n",
    "    infer_requests = [InferRequest(**data)]\n",
    "    response = infer_batch(engine, infer_requests)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_question)):\n",
    "    question = df_question.loc[i,'question']\n",
    "    document_name = df_question.loc[i,'document']\n",
    "    options = df_question.loc[i,'options']\n",
    "    true_answer = df_question.loc[i,'answer']\n",
    "    full_question = question + ' '.join(options)\n",
    "    if \"第\" in question and \"页\" in question and \"图\": # 问题含有图片\n",
    "        pic_page_num = re.findall(r\"第(\\d+)页\", question)[0]\n",
    "        pic_page_num = int(pic_page_num)\n",
    "        answer = get_mix_answer(document_name,pic_page_num,question,options,i)\n",
    "    else:\n",
    "        text_answer = get_text_answer(document_name,question,options,i) # 使用文本来回答\n",
    "        image_answer = get_img_answer(document_name,question,options,i) # 使用图像来回答\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
